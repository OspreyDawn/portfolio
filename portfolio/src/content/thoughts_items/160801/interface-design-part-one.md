## Part 1: Understanding Interfaces

Interfaces are systems that we interact with to exert influence or to come to an understanding of a particular thing.

The world we live in has an interface. When we navigate it, we do so through analysation of data collected by our senses and combine it with our inherent knowledge. There are the usual senses people can identify which are the most obvious like sight, sound, touch, taste and smell. However, there are an abundance of others that are implicit in the everyday. Senses like thermo-reception (the ability to detect temperature) and proprioception (the ability to sense where your body is in space). As soon as we enter the digital world however, we lose almost all of our senses; we are primarily relying on learned knowledge accumulated through past experiences.

Vision is the primary sense stimulated through modern digital UI. Sometimes sound is present through speakers and even rarer still is the use of touch through vibration. These seem to be the only three senses stimulated in mainstream digital devices. Out of the three, vision is the only sense that permeates all digital experiences that humans encounter on a daily basis; one sense out of many. Digital interfaces not only have to account for this lack of sensorial input but they do so relying purely on visual methods. This puts enormous strain on a user's inherent knowledge to navigate it. Since the life knowledge of the everyday user varies wildly so does the effective mileage of any given interface.

### A Brief History of Interaction

There's a reason why Apple used skeuomorphism when they first released the iPhone. The visual replication of real, tangible objects in a digital interface to communicate how one might interact with them in an intuitive way makes sense. Certain physical objects provide affordances that contextual-less digital artefacts cannot. Prior to the iPhone, there had been no uniform visual language to relay how one might interact with an interface completely reliant on touch. The Notepad app looking like an actual note pad, with yellow paper pages and stitching, is an example of this. Buttons had visual cues to make them look three dimensional that depressed when touched much like one would expect to see in the real world. When iOS was first released they had to communicate how to navigate the world that they had created in terms that they knew the everyday user could understand.


<div class="gallery vertical">
  <iron-image class="galleryItem" style="background-color: white" sizing="contain" preload fade src="/src/content/thoughts_items/160801/gallery/skeuo-vs-flat.jpg"></iron-image>
</div>

This is not the first time this has happened either; think of the traditional desktop user interface. Developed in the early 70’s, researchers at Xerox PARC had created the first graphical user interface, and the mouse to go with it, using the same principles. The screen represented an actual desk, data was given names like 'files' and 'folders' which, at the time, had no meaning in a digital sense. The ‘windows’ on the screen were the files layered on top each other as one might expect on top of a desk. As time has progressed the language has been learned and streamlined for both the desktop and mobile interfaces, sometimes at the expense of the user. This is not due to malice. Assuming users understand interface patterns that came before, designers can streamline task flows but they are just as likely to cause confusion. After all, assuming anything is the first mental block on the path to elegant design.

<div class="gallery vertical">
  <iron-image class="galleryItem" style="background-color: #0A0203" sizing="contain" preload fade src="/src/content/thoughts_items/160801/gallery/xerox-star-ui.jpg"></iron-image>
</div>

### How Humans Interact with the Worlds they Inhabit

Interfaces should acknowledge users navigate their worlds through their senses combined with the knowledge accumulated through them over prior experiences. How well it is executed can be judged on these terms.

So how exactly do humans interact with the worlds they inhabit, digital or otherwise? First, a user has a goal in mind that they want to achieve. Then, that user has to act upon the world; they have to manipulate something or someone with their goal in mind. Finally, a user must check that the actions they executed resulted in the accomplishment of their goal. This is the basis of how people navigate the world around them that Don Norman describes in greater detail as 'the Seven Stages of Action' in his seminal book 'The Design of Everyday Things.' The seven stages are:

* Forming the Goal
* Forming the Intention
* Specifying an Action
* Executing the Action
* Perceiving the State of the World
* Interpreting the State of the World
* Evaluating the Outcome

This is only an approximate model, but it serves well as a way of evaluating the behaviours of any given user. Sometimes these actions are completed in a matter of seconds, sometimes they occur over longer periods of time. Sometimes they are planned, sometimes they are spontaneous. Other times, completed goals feed into others once one is completed creating subgoals and constant feedback loops. What is certain is that someone, somewhere, is at one of these stages at any one time, one way or another. How easy it is for any given user to achieve their goals can be measured in the gulfs of both execution and evaluation of their expectations.

> *“Does a system provide actions that correspond to the intentions of a person? The difference between the intentions and allowable actions is the Gulf of Execution…”*

> *“Does the system provide a physical representation that can be directly perceived and that is directly interpretable in terms of the intentions and expectations of the person? The Gulf of Evaluation reflects the amount of effort that the person must exert to interpret the physical state of the system and to determine how well the expectations and intentions have been met.”*

> *The Design of Everyday Things - Don Norman*

<div class="gallery vertical">
  <iron-image class="galleryItem" style="background-color: white; margin-bottom: -2rem; position: relative; z-index: -1;" sizing="contain" preload fade src="/src/content/thoughts_items/160801/gallery/doet.jpg"></iron-image>
</div>

<p style="margin-top: -3rem;">The more seamless an interface, or system as Norman describes, the easier it is for someone to execute their goal and evaluate a system's effects. The easier it is to determine whether the desirable results are met is what differentiates a well designed interface from a bad one. An interface is what ever a person interacts with to achieve their goal. A door’s handle is as much an interface as an app's GUI is.</p>

### Interfaces are a Language

Interfaces can be digital, physical or both; each comes with its own strengths, weaknesses and limitations. The greatest benefit of a digital interface is its flexibility; it is able to change the way it looks and functions based on the context it is in. Ideally this flexible nature provides users the most useful and relevant options at the right time. But with flexibility comes with complexity that needs to be carefully managed so that users don't get lost.

So how do you manage this complexity? Look to the natural world. It runs by consistent logic that has its own established affordances and laws created over billions of years. These can be used to communicate specific messages in a physical interface and have contributed to human instinct over millennia. Vibrant colours in wildlife naturally draw our attention to warn us. A ripe apple falls from a tree the same way a nut does due to gravity. A digital interface needs to have its own consistent logic or language that people can learn to trust and predict when they execute and evaluate any given action they take. An interface is a language and needs to behave as such.

The Oxford Dictionary defines language as 'the system of communication used by a particular community.' When you design an interface your community is your users. You are communicating what they can and cannot do. You are providing the tool that allows them to execute and evaluate those actions. Language is the tool that establishes these expectations; design is therefore a language. A good interface language is an elegant language; a language where related actions are grouped, where items of a familiar nature can be acted upon in similar, expected ways. The more inconsistent a language is, the more exceptions there are and the harder it is to learn and the more afraid users are to trust it. It is one of the major reasons why English is can be hard to learn as a second language. That's why it's often best to piggy back established interface  conventions over truly unique ones. To create a new one requires extensive effort teaching it and should only be done if absolutely necessary, and even then only sparingly.

An interface language can be inherently complex, especially if you are trying to help a user solve a complex problem. That doesn't mean it has to be difficult to learn. Complexity is not the antithesis to simplicity, they are qualia that define different levels of understanding.  A designer needs to understand a system fully to help a user navigate it with as little effort as possible. That is simplicity. The objective is not to reduce, to a minimum, the number of required actions to be taken. The objective is to help achieve a goal as accurately as possible with the least cognitive stress. Elegance is understanding complexity well enough to lead a user with confidence. An interface should be judged by how elegantly it achieves the users' goals, rather than how simple it appears.

Understanding the complexity of a system requires an intimate knowledge of it from the view of those most concerned with the problem: the users themselves. Everyone forms some sort of goal when they want to do something. The problem might be they're not quite sure how to achieve their goal; the gulfs of execution and evaluation are too wide for them to make any headway. To begin solving these problems, we need to understand why that person has formed that goal in the first place. While everyone has a goal, the nature and intent of those goals are each individual cases that need to be understood. The seven stages of action provide reasonable perspective on *how* people go about trying to solve their problems but don't provide enough insight into the *why* and that's where doing a bit of user research comes in.

In the next part in this series, I will use experience from an interface I helped design for a mobile banking application to put these thoughts into context.

[Part 2: How Sense & Language Come Together to Make An Elegant Interface.](#/thoughts/160808)
